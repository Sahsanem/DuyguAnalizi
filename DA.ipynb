{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLfJoPm5RTlx4GfnFRpZb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahsanem/DuyguAnalizi/blob/main/DA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqI7YWGMLDTs",
        "outputId": "10448edb-49f9-46bf-bd26-7849ddecdca2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay102KQFMI4r",
        "outputId": "b92b9989-405b-4c1d-811c-cdd38a9b8e61"
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "# pd.set_option('display.max_rows', 500)\n",
        "# pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)\n",
        "\n",
        "df=pd.read_csv('gdrive/My Drive/DuyguTanima/fer2013/fer2013.csv')\n",
        "\n",
        "# print(df.info())\n",
        "# print(df[\"Usage\"].value_counts())\n",
        "\n",
        "# print(df.head())\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 50 #200\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "#cannot produce\n",
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "# print(f\"shape:{X_train.shape}\")\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "449/449 [==============================] - 526s 1s/step - loss: 1.7688 - accuracy: 0.2721 - val_loss: 1.5328 - val_accuracy: 0.3976\n",
            "Epoch 2/50\n",
            "449/449 [==============================] - 515s 1s/step - loss: 1.5087 - accuracy: 0.4056 - val_loss: 1.4128 - val_accuracy: 0.4581\n",
            "Epoch 3/50\n",
            "449/449 [==============================] - 515s 1s/step - loss: 1.3949 - accuracy: 0.4573 - val_loss: 1.3011 - val_accuracy: 0.5035\n",
            "Epoch 4/50\n",
            "449/449 [==============================] - 517s 1s/step - loss: 1.3340 - accuracy: 0.4842 - val_loss: 1.2633 - val_accuracy: 0.5099\n",
            "Epoch 5/50\n",
            "449/449 [==============================] - 518s 1s/step - loss: 1.2749 - accuracy: 0.5112 - val_loss: 1.2260 - val_accuracy: 0.5185\n",
            "Epoch 6/50\n",
            "449/449 [==============================] - 519s 1s/step - loss: 1.2356 - accuracy: 0.5249 - val_loss: 1.1899 - val_accuracy: 0.5319\n",
            "Epoch 7/50\n",
            "449/449 [==============================] - 517s 1s/step - loss: 1.2036 - accuracy: 0.5377 - val_loss: 1.1892 - val_accuracy: 0.5433\n",
            "Epoch 8/50\n",
            "449/449 [==============================] - 517s 1s/step - loss: 1.1788 - accuracy: 0.5507 - val_loss: 1.1795 - val_accuracy: 0.5419\n",
            "Epoch 9/50\n",
            "449/449 [==============================] - 516s 1s/step - loss: 1.1445 - accuracy: 0.5653 - val_loss: 1.1425 - val_accuracy: 0.5678\n",
            "Epoch 10/50\n",
            "449/449 [==============================] - 518s 1s/step - loss: 1.1182 - accuracy: 0.5769 - val_loss: 1.1458 - val_accuracy: 0.5534\n",
            "Epoch 11/50\n",
            "449/449 [==============================] - 518s 1s/step - loss: 1.1020 - accuracy: 0.5769 - val_loss: 1.1377 - val_accuracy: 0.5595\n",
            "Epoch 12/50\n",
            "449/449 [==============================] - 518s 1s/step - loss: 1.0749 - accuracy: 0.5901 - val_loss: 1.1549 - val_accuracy: 0.5614\n",
            "Epoch 13/50\n",
            "449/449 [==============================] - 518s 1s/step - loss: 1.0634 - accuracy: 0.5920 - val_loss: 1.1450 - val_accuracy: 0.5667\n",
            "Epoch 14/50\n",
            "449/449 [==============================] - 519s 1s/step - loss: 1.0386 - accuracy: 0.6061 - val_loss: 1.1312 - val_accuracy: 0.5706\n",
            "Epoch 15/50\n",
            "449/449 [==============================] - 516s 1s/step - loss: 1.0154 - accuracy: 0.6154 - val_loss: 1.1405 - val_accuracy: 0.5715\n",
            "Epoch 16/50\n",
            "449/449 [==============================] - 516s 1s/step - loss: 1.0020 - accuracy: 0.6158 - val_loss: 1.1459 - val_accuracy: 0.5656\n",
            "Epoch 17/50\n",
            "449/449 [==============================] - 517s 1s/step - loss: 0.9937 - accuracy: 0.6248 - val_loss: 1.1482 - val_accuracy: 0.5756\n",
            "Epoch 18/50\n",
            "449/449 [==============================] - 516s 1s/step - loss: 0.9740 - accuracy: 0.6275 - val_loss: 1.1690 - val_accuracy: 0.5706\n",
            "Epoch 19/50\n",
            "449/449 [==============================] - 518s 1s/step - loss: 0.9694 - accuracy: 0.6305 - val_loss: 1.1458 - val_accuracy: 0.5826\n",
            "Epoch 20/50\n",
            "449/449 [==============================] - 517s 1s/step - loss: 0.9338 - accuracy: 0.6408 - val_loss: 1.1477 - val_accuracy: 0.5759\n",
            "Epoch 21/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.9267 - accuracy: 0.6489 - val_loss: 1.1652 - val_accuracy: 0.5743\n",
            "Epoch 22/50\n",
            "449/449 [==============================] - 521s 1s/step - loss: 0.9110 - accuracy: 0.6537 - val_loss: 1.1622 - val_accuracy: 0.5751\n",
            "Epoch 23/50\n",
            "449/449 [==============================] - 519s 1s/step - loss: 0.8977 - accuracy: 0.6570 - val_loss: 1.1889 - val_accuracy: 0.5723\n",
            "Epoch 24/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.8850 - accuracy: 0.6633 - val_loss: 1.1814 - val_accuracy: 0.5692\n",
            "Epoch 25/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.8512 - accuracy: 0.6729 - val_loss: 1.1839 - val_accuracy: 0.5759\n",
            "Epoch 26/50\n",
            "449/449 [==============================] - 519s 1s/step - loss: 0.8487 - accuracy: 0.6754 - val_loss: 1.1724 - val_accuracy: 0.5818\n",
            "Epoch 27/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.8221 - accuracy: 0.6868 - val_loss: 1.1897 - val_accuracy: 0.5790\n",
            "Epoch 28/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.8241 - accuracy: 0.6844 - val_loss: 1.2336 - val_accuracy: 0.5729\n",
            "Epoch 29/50\n",
            "449/449 [==============================] - 519s 1s/step - loss: 0.8192 - accuracy: 0.6888 - val_loss: 1.2079 - val_accuracy: 0.5737\n",
            "Epoch 30/50\n",
            "449/449 [==============================] - 522s 1s/step - loss: 0.7919 - accuracy: 0.7024 - val_loss: 1.2243 - val_accuracy: 0.5821\n",
            "Epoch 31/50\n",
            "449/449 [==============================] - 521s 1s/step - loss: 0.7882 - accuracy: 0.7018 - val_loss: 1.2112 - val_accuracy: 0.5706\n",
            "Epoch 32/50\n",
            "449/449 [==============================] - 521s 1s/step - loss: 0.7666 - accuracy: 0.7124 - val_loss: 1.2112 - val_accuracy: 0.5851\n",
            "Epoch 33/50\n",
            "449/449 [==============================] - 519s 1s/step - loss: 0.7695 - accuracy: 0.7118 - val_loss: 1.2399 - val_accuracy: 0.5770\n",
            "Epoch 34/50\n",
            "449/449 [==============================] - 521s 1s/step - loss: 0.7569 - accuracy: 0.7150 - val_loss: 1.2530 - val_accuracy: 0.5840\n",
            "Epoch 35/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.7288 - accuracy: 0.7222 - val_loss: 1.2876 - val_accuracy: 0.5737\n",
            "Epoch 36/50\n",
            "449/449 [==============================] - 523s 1s/step - loss: 0.7196 - accuracy: 0.7321 - val_loss: 1.2843 - val_accuracy: 0.5762\n",
            "Epoch 37/50\n",
            "449/449 [==============================] - 522s 1s/step - loss: 0.7157 - accuracy: 0.7301 - val_loss: 1.2511 - val_accuracy: 0.5768\n",
            "Epoch 38/50\n",
            "449/449 [==============================] - 523s 1s/step - loss: 0.7103 - accuracy: 0.7365 - val_loss: 1.2788 - val_accuracy: 0.5717\n",
            "Epoch 39/50\n",
            "449/449 [==============================] - 522s 1s/step - loss: 0.6918 - accuracy: 0.7387 - val_loss: 1.2843 - val_accuracy: 0.5790\n",
            "Epoch 40/50\n",
            "449/449 [==============================] - 523s 1s/step - loss: 0.6788 - accuracy: 0.7466 - val_loss: 1.2693 - val_accuracy: 0.5885\n",
            "Epoch 41/50\n",
            "449/449 [==============================] - 522s 1s/step - loss: 0.6655 - accuracy: 0.7491 - val_loss: 1.2849 - val_accuracy: 0.5754\n",
            "Epoch 42/50\n",
            "449/449 [==============================] - 517s 1s/step - loss: 0.6604 - accuracy: 0.7492 - val_loss: 1.2768 - val_accuracy: 0.5768\n",
            "Epoch 43/50\n",
            "449/449 [==============================] - 518s 1s/step - loss: 0.6488 - accuracy: 0.7583 - val_loss: 1.3598 - val_accuracy: 0.5731\n",
            "Epoch 44/50\n",
            "449/449 [==============================] - 516s 1s/step - loss: 0.6456 - accuracy: 0.7569 - val_loss: 1.3261 - val_accuracy: 0.5787\n",
            "Epoch 45/50\n",
            "449/449 [==============================] - 521s 1s/step - loss: 0.6412 - accuracy: 0.7625 - val_loss: 1.3405 - val_accuracy: 0.5770\n",
            "Epoch 46/50\n",
            "449/449 [==============================] - 524s 1s/step - loss: 0.6311 - accuracy: 0.7651 - val_loss: 1.3021 - val_accuracy: 0.5848\n",
            "Epoch 47/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.6233 - accuracy: 0.7679 - val_loss: 1.3380 - val_accuracy: 0.5807\n",
            "Epoch 48/50\n",
            "449/449 [==============================] - 519s 1s/step - loss: 0.6153 - accuracy: 0.7719 - val_loss: 1.3166 - val_accuracy: 0.5754\n",
            "Epoch 49/50\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.6016 - accuracy: 0.7771 - val_loss: 1.3621 - val_accuracy: 0.5812\n",
            "Epoch 50/50\n",
            "449/449 [==============================] - 521s 1s/step - loss: 0.5867 - accuracy: 0.7838 - val_loss: 1.3634 - val_accuracy: 0.5720\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BhjSLZpXA7w",
        "outputId": "d0b58cf3-284b-46ba-caf4-1e02872bc9f6"
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "# pd.set_option('display.max_rows', 500)\n",
        "# pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)\n",
        "\n",
        "df=pd.read_csv('gdrive/My Drive/DuyguTanima/fer2013/fer2013.csv')\n",
        "\n",
        "# print(df.info())\n",
        "# print(df[\"Usage\"].value_counts())\n",
        "\n",
        "# print(df.head())\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "#cannot produce\n",
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "# print(f\"shape:{X_train.shape}\")\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "449/449 [==============================] - 525s 1s/step - loss: 1.7692 - accuracy: 0.2707 - val_loss: 1.5414 - val_accuracy: 0.3931\n",
            "Epoch 2/30\n",
            "449/449 [==============================] - 520s 1s/step - loss: 1.5173 - accuracy: 0.4043 - val_loss: 1.3676 - val_accuracy: 0.4706\n",
            "Epoch 3/30\n",
            "449/449 [==============================] - 520s 1s/step - loss: 1.3983 - accuracy: 0.4597 - val_loss: 1.3149 - val_accuracy: 0.4960\n",
            "Epoch 4/30\n",
            "449/449 [==============================] - 521s 1s/step - loss: 1.3281 - accuracy: 0.4884 - val_loss: 1.2594 - val_accuracy: 0.5132\n",
            "Epoch 5/30\n",
            "449/449 [==============================] - 524s 1s/step - loss: 1.2798 - accuracy: 0.5066 - val_loss: 1.2693 - val_accuracy: 0.5155\n",
            "Epoch 6/30\n",
            "449/449 [==============================] - 526s 1s/step - loss: 1.2416 - accuracy: 0.5267 - val_loss: 1.2206 - val_accuracy: 0.5297\n",
            "Epoch 7/30\n",
            "449/449 [==============================] - 525s 1s/step - loss: 1.2000 - accuracy: 0.5348 - val_loss: 1.2228 - val_accuracy: 0.5375\n",
            "Epoch 8/30\n",
            "449/449 [==============================] - 526s 1s/step - loss: 1.1872 - accuracy: 0.5439 - val_loss: 1.2183 - val_accuracy: 0.5272\n",
            "Epoch 9/30\n",
            "449/449 [==============================] - 527s 1s/step - loss: 1.1634 - accuracy: 0.5515 - val_loss: 1.1633 - val_accuracy: 0.5553\n",
            "Epoch 10/30\n",
            "449/449 [==============================] - 531s 1s/step - loss: 1.1404 - accuracy: 0.5658 - val_loss: 1.1889 - val_accuracy: 0.5464\n",
            "Epoch 11/30\n",
            "449/449 [==============================] - 528s 1s/step - loss: 1.1041 - accuracy: 0.5771 - val_loss: 1.1613 - val_accuracy: 0.5592\n",
            "Epoch 12/30\n",
            "449/449 [==============================] - 528s 1s/step - loss: 1.0899 - accuracy: 0.5883 - val_loss: 1.1584 - val_accuracy: 0.5620\n",
            "Epoch 13/30\n",
            "449/449 [==============================] - 527s 1s/step - loss: 1.0668 - accuracy: 0.5944 - val_loss: 1.1579 - val_accuracy: 0.5628\n",
            "Epoch 14/30\n",
            "449/449 [==============================] - 526s 1s/step - loss: 1.0555 - accuracy: 0.5935 - val_loss: 1.1547 - val_accuracy: 0.5626\n",
            "Epoch 15/30\n",
            "449/449 [==============================] - 532s 1s/step - loss: 1.0340 - accuracy: 0.6058 - val_loss: 1.1709 - val_accuracy: 0.5614\n",
            "Epoch 16/30\n",
            "449/449 [==============================] - 528s 1s/step - loss: 1.0133 - accuracy: 0.6125 - val_loss: 1.1804 - val_accuracy: 0.5495\n",
            "Epoch 17/30\n",
            "449/449 [==============================] - 529s 1s/step - loss: 0.9893 - accuracy: 0.6273 - val_loss: 1.1902 - val_accuracy: 0.5517\n",
            "Epoch 18/30\n",
            "449/449 [==============================] - 525s 1s/step - loss: 0.9806 - accuracy: 0.6270 - val_loss: 1.1415 - val_accuracy: 0.5743\n",
            "Epoch 19/30\n",
            "449/449 [==============================] - 526s 1s/step - loss: 0.9533 - accuracy: 0.6395 - val_loss: 1.1468 - val_accuracy: 0.5815\n",
            "Epoch 20/30\n",
            "449/449 [==============================] - 526s 1s/step - loss: 0.9417 - accuracy: 0.6368 - val_loss: 1.1450 - val_accuracy: 0.5759\n",
            "Epoch 21/30\n",
            "449/449 [==============================] - 527s 1s/step - loss: 0.9166 - accuracy: 0.6483 - val_loss: 1.1723 - val_accuracy: 0.5673\n",
            "Epoch 22/30\n",
            "449/449 [==============================] - 529s 1s/step - loss: 0.9038 - accuracy: 0.6568 - val_loss: 1.1609 - val_accuracy: 0.5768\n",
            "Epoch 23/30\n",
            "449/449 [==============================] - 522s 1s/step - loss: 0.8852 - accuracy: 0.6685 - val_loss: 1.2088 - val_accuracy: 0.5639\n",
            "Epoch 24/30\n",
            "449/449 [==============================] - 522s 1s/step - loss: 0.8704 - accuracy: 0.6696 - val_loss: 1.2107 - val_accuracy: 0.5737\n",
            "Epoch 25/30\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.8629 - accuracy: 0.6713 - val_loss: 1.1936 - val_accuracy: 0.5704\n",
            "Epoch 26/30\n",
            "449/449 [==============================] - 521s 1s/step - loss: 0.8467 - accuracy: 0.6786 - val_loss: 1.2041 - val_accuracy: 0.5762\n",
            "Epoch 27/30\n",
            "449/449 [==============================] - 522s 1s/step - loss: 0.8258 - accuracy: 0.6822 - val_loss: 1.1963 - val_accuracy: 0.5754\n",
            "Epoch 28/30\n",
            "449/449 [==============================] - 523s 1s/step - loss: 0.8171 - accuracy: 0.6871 - val_loss: 1.2382 - val_accuracy: 0.5734\n",
            "Epoch 29/30\n",
            "449/449 [==============================] - 520s 1s/step - loss: 0.7826 - accuracy: 0.7031 - val_loss: 1.1979 - val_accuracy: 0.5871\n",
            "Epoch 30/30\n",
            "449/449 [==============================] - 523s 1s/step - loss: 0.7812 - accuracy: 0.7003 - val_loss: 1.2350 - val_accuracy: 0.5815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxAsHDxuOjUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112d8e80-f101-4b2e-f856-bea96f23eac9"
      },
      "source": [
        "scores = model.evaluate(np.array(X_test), np.array(test_y), batch_size=batch_size)\n",
        "print(\"Loss: \" + str(scores[0]))\n",
        "print(\"Accuracy: \" + str(100*scores[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 15s 261ms/step - loss: 1.2064 - accuracy: 0.5834\n",
            "Loss: 1.2064000368118286\n",
            "Accuracy: 58.34494233131409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LREdWRGOn2gF",
        "outputId": "f121f065-b5e0-47a4-ab28-89fca29f0611"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 18, 18, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 9, 9, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 5, 5, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 1,914,951\n",
            "Trainable params: 1,914,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRqrZVGPgraR",
        "outputId": "57db214e-5e6d-440e-bdcd-6636a2139021"
      },
      "source": [
        "scores = model.evaluate(np.array(X_train), np.array(train_y), batch_size=batch_size)\n",
        "print(\"Loss: \" + str(scores[0]))\n",
        "print(\"Accuracy: \" + str(100*scores[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "449/449 [==============================] - 120s 267ms/step - loss: 0.5564 - accuracy: 0.8166\n",
            "Loss: 0.5564154982566833\n",
            "Accuracy: 81.65732026100159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68RCr3QTlQdy"
      },
      "source": [
        "#grafik\n",
        "from matplotlib import pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(14,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "A1fQy658FqC3",
        "outputId": "386f4a2c-a216-449c-b9a4-52b0ea34682f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "test_img_path = (\"gdrive/My Drive/DuyguTanima/Veriseti/Test/dogal3.jpeg\") #igrenme3 8 korku6 2 mutlu12 mutlu9 uzgun4 uzgun5 8 saskin3 saskin5 dogal3 dogal5\n",
        "\n",
        "img_orj = image.load_img(test_img_path)\n",
        "img = image.load_img(test_img_path, grayscale=True, target_size=(48, 48))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "x /= 255\n",
        "\n",
        "custom = model.predict(x)\n",
        "#Duygu Analizi(custom[0])\n",
        "\n",
        "\n",
        "#1\n",
        "objects = ('kızgın', 'iğrenme', 'korku', 'mutlu', 'üzgün', 'şaşırma', 'doğal')\n",
        "y_pos = np.arange(len(objects))\n",
        "    \n",
        "plt.bar(y_pos, custom[0], align='center', alpha=0.5, color='g')\n",
        "plt.xticks(y_pos, objects)\n",
        "plt.ylabel('yüzde')\n",
        "plt.title('duygu')\n",
        "plt.show()\n",
        "\n",
        "#2\n",
        "x = np.array(x, 'float32')\n",
        "x = x.reshape([48, 48]);\n",
        "plt.axis('off')\n",
        "plt.gray()\n",
        "plt.imshow(img_orj)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bd9b3d1ac645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtest_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"gdrive/My Drive/DuyguTanima/Veriseti/Test/dogal3.jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#igrenme3 8 korku6 2 mutlu12 mutlu9 uzgun4 uzgun5 8 saskin3 saskin5 dogal3 dogal5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mimg_orj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    291\u001b[0m   \"\"\"\n\u001b[1;32m    292\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 293\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gdrive/My Drive/DuyguTanima/Veriseti/Test/dogal3.jpeg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q34f19HOMi1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "96ff918e-9fe1-4aa3-92d2-0954f53bad00"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#load model\n",
        "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
        "#load weights\n",
        "model.load_weights('fer.h5')\n",
        "\n",
        "\n",
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
        "    if not ret:\n",
        "        continue\n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
        "\n",
        "\n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "        img_pixels = image.img_to_array(roi_gray)\n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "        img_pixels /= 255\n",
        "\n",
        "        predictions = model.predict(img_pixels)\n",
        "\n",
        "        #find max indexed array\n",
        "        max_index = np.argmax(predictions[0])\n",
        "\n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "        predicted_emotion = emotions[max_index]\n",
        "\n",
        "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))\n",
        "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-156f7c35c95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# captures frame and returns boolean value and captured image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}